{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name : Chathumini B.G.D.T.\n",
    "\n",
    "Index Number : 190107T\n",
    "\n",
    "Github Repo:\n",
    "https://github.com/dulmi-19/Image-Processing-and-Machine-Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape:  (60000, 32, 32)\n",
      "train_labels.shape:  (60000,)\n",
      "test_images.shape: (10000, 32, 32)\n",
      "test_labels.shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Padding\n",
    "paddings = tf.constant([[0, 0], [2, 2], [2, 2]])\n",
    "train_images = tf.pad(train_images, paddings, constant_values=0)\n",
    "test_images = tf.pad(test_images, paddings, constant_values=0)\n",
    "\n",
    "print('train_images.shape: ', train_images.shape)\n",
    "print('train_labels.shape: ', train_labels.shape)\n",
    "print('test_images.shape:', test_images.shape)\n",
    "print('test_labels.shape:', test_labels.shape)\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "train_images = tf.dtypes.cast(train_images, tf.float32)\n",
    "test_images = tf.dtypes.cast(test_images, tf.float32)\n",
    "train_images, test_images = train_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for j in range(25):\n",
    "    plt.subplot(5,5,j+1)\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(tf.reshape(test_images[j],[32,32]),cmap=plt.cm.gray)\n",
    "    plt.xlabel(class_names[test_labels[j]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000020F7258BC10>>\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.2244 - accuracy: 0.9314\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0722 - accuracy: 0.9777\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 26s 14ms/step - loss: 0.0519 - accuracy: 0.9838\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0417 - accuracy: 0.9868\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 0.0319 - accuracy: 0.9898\n",
      "313/313 - 2s - loss: 0.0389 - accuracy: 0.9880 - 2s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(6,(5,5),activation = 'relu',input_shape = (32,32,1)))\n",
    "model.add(layers.AveragePooling2D((2,2)))\n",
    "model.add(layers.Conv2D(16,(5,5),activation = 'relu'))\n",
    "model.add(layers.AveragePooling2D((2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(120,activation = 'relu'))\n",
    "model.add(layers.Dense(84,activation = 'relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer = 'adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model.summary)\n",
    "model.fit(train_images,train_labels,epochs = 5)\n",
    "test_loss, test_accuracy = model.evaluate(test_images,test_labels,verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CIFAR10\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.datasets import cifar10, mnist\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000020F488F4DC0>>\n",
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 71s 44ms/step - loss: 1.6020 - accuracy: 0.4129\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 1.2518 - accuracy: 0.5524\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.0826 - accuracy: 0.6189\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.9728 - accuracy: 0.6603\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.8935 - accuracy: 0.6867\n",
      "313/313 - 4s - loss: 0.9946 - accuracy: 0.6574 - 4s/epoch - 12ms/step\n",
      "0.6574000120162964\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(5,5),activation = 'relu',input_shape = (32,32,3)))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(128,(3,3),activation = 'relu'))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation = 'relu'))\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate = 0.001),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model.summary)\n",
    "\n",
    "model.fit(train_images,train_labels,epochs = 5)\n",
    "test_loss, test_accuracy = model.evaluate(test_images,test_labels,verbose = 2)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images.shape:  (60000, 32, 32)\n",
      "train_labels.shape:  (60000,)\n",
      "test_images.shape: (10000, 32, 32)\n",
      "test_labels.shape: (10000,)\n",
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000020F720A5B70>>\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 67s 35ms/step - loss: 0.1372 - accuracy: 0.9581\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0444 - accuracy: 0.9865\n",
      "313/313 - 3s - loss: 0.0458 - accuracy: 0.9849 - 3s/epoch - 11ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Padding\n",
    "paddings = tf.constant([[0, 0], [2, 2], [2, 2]])\n",
    "train_images = tf.pad(train_images, paddings, constant_values=0)\n",
    "test_images = tf.pad(test_images, paddings, constant_values=0)\n",
    "\n",
    "print('train_images.shape: ', train_images.shape)\n",
    "print('train_labels.shape: ', train_labels.shape)\n",
    "print('test_images.shape:', test_images.shape)\n",
    "print('test_labels.shape:', test_labels.shape)\n",
    "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "\n",
    "train_images = tf.dtypes.cast(train_images, tf.float32)\n",
    "test_images = tf.dtypes.cast(test_images, tf.float32)\n",
    "train_images, test_images = train_images[..., np.newaxis]/255.0, test_images[..., np.newaxis]/255.0\n",
    "\n",
    "model_base = models.Sequential()\n",
    "model_base.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (32,32,1)))\n",
    "model_base.add(layers.MaxPool2D((2,2)))\n",
    "model_base.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model_base.add(layers.MaxPool2D((2,2)))\n",
    "model_base.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "\n",
    "model_base.add(layers.Flatten())\n",
    "model_base.add(layers.Dense(64,activation = 'relu'))\n",
    "model_base.add(layers.Dense(10))\n",
    "\n",
    "model_base.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model_base.summary)\n",
    "\n",
    "model_base.fit(train_images,train_labels,epochs = 2)\n",
    "test_loss, test_accuracy = model_base.evaluate(test_images,test_labels,verbose = 2)\n",
    "model_base.save_weights('saved_weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x0000020F72322350>>\n",
      "Epoch 1/2\n",
      "1875/1875 [==============================] - 65s 34ms/step - loss: 0.1314 - accuracy: 0.9608\n",
      "Epoch 2/2\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.0430 - accuracy: 0.9873\n",
      "313/313 - 4s - loss: 0.0459 - accuracy: 0.9843 - 4s/epoch - 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "model_lw = models.Sequential()\n",
    "model_lw.add(layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (32,32,1)))\n",
    "model_lw.add(layers.MaxPool2D((2,2)))\n",
    "model_lw.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "model_lw.add(layers.MaxPool2D((2,2)))\n",
    "model_lw.add(layers.Conv2D(64,(3,3),activation = 'relu'))\n",
    "\n",
    "model_lw.add(layers.Flatten())\n",
    "model_lw.add(layers.Dense(64,activation = 'relu'))\n",
    "model_lw.add(layers.Dense(10))\n",
    "\n",
    "model_lw.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(model_lw.summary)\n",
    "\n",
    "model_lw.fit(train_images,train_labels,epochs = 2)\n",
    "test_loss, test_accuracy = model_lw.evaluate(test_images,test_labels,verbose = 2)\n",
    "model_lw.save('saved_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 30, 30, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 15, 15, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                65600     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121,994\n",
      "Trainable params: 121,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "313/313 - 3s - loss: 0.0459 - accuracy: 0.9843 - 3s/epoch - 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04589089751243591, 0.9843000173568726]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the model\n",
    "model_ld = keras.models.load_model('saved_model/')\n",
    "print(model_ld.summary())\n",
    "model_ld.evaluate(test_images,test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.functional.Functional object at 0x0000020F72378370>>\n",
      "Epoch 1/3\n",
      "1875/1875 - 58s - loss: 0.0702 - accuracy: 0.9793 - 58s/epoch - 31ms/step\n",
      "Epoch 2/3\n",
      "1875/1875 - 57s - loss: 0.0261 - accuracy: 0.9918 - 57s/epoch - 30ms/step\n",
      "Epoch 3/3\n",
      "1875/1875 - 57s - loss: 0.0197 - accuracy: 0.9937 - 57s/epoch - 30ms/step\n",
      "313/313 - 3s - loss: 0.0261 - accuracy: 0.9923 - 3s/epoch - 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02605402283370495, 0.9922999739646912]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_inputs = model_ld.layers[0].input\n",
    "base_outputs = model_ld.layers[-2].output\n",
    "output = layers.Dense(10)(base_outputs)\n",
    "\n",
    "new_model = keras.Model(inputs=base_inputs, outputs = output)\n",
    "new_model.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "print(new_model.summary)\n",
    "\n",
    "new_model.fit(train_images,train_labels,epochs = 3,verbose = 2)\n",
    "new_model.evaluate(test_images, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1875/1875 - 20s - loss: 0.2647 - accuracy: 0.9391 - 20s/epoch - 11ms/step\n",
      "Epoch 2/3\n",
      "1875/1875 - 19s - loss: 0.0253 - accuracy: 0.9931 - 19s/epoch - 10ms/step\n",
      "Epoch 3/3\n",
      "1875/1875 - 20s - loss: 0.0202 - accuracy: 0.9940 - 20s/epoch - 10ms/step\n",
      "313/313 - 3s - loss: 0.0259 - accuracy: 0.9923 - 3s/epoch - 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.025881975889205933, 0.9922999739646912]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transfer learning\n",
    "model_for_tl =keras.models.load_model('saved_model/')\n",
    "model_for_tl.trainable = False\n",
    "for layer in model_for_tl.layers:\n",
    "    assert layer.trainable == False\n",
    "\n",
    "base_inputs = model_for_tl.layers[0].input\n",
    "base_outputs = model_for_tl.layers[-2].output\n",
    "output = layers.Dense(10)(base_outputs)\n",
    "\n",
    "new_model = keras.Model(inputs=base_inputs, outputs = output)\n",
    "new_model.compile(optimizer =keras.optimizers.Adam(),loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics = ['accuracy'])\n",
    "\n",
    "new_model.fit(train_images,train_labels,epochs = 3,verbose = 2)\n",
    "new_model.evaluate(test_images, test_labels, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (BatchN  (None, 56, 56, 64)  256         ['pool1_pool[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (Acti  (None, 56, 56, 64)  0           ['conv2_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4096        ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_conv[0][0]',    \n",
      "                                                                  'conv2_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36864       ['conv2_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (BatchN  (None, 56, 56, 256)  1024       ['conv2_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (Acti  (None, 56, 56, 256)  0          ['conv2_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16384       ['conv2_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPaddin  (None, 58, 58, 64)  0           ['conv2_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 28, 28, 64)   36864       ['conv2_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 28, 28, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 28, 28, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooling2D  (None, 28, 28, 256)  0          ['conv2_block2_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 28, 28, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)         (None, 28, 28, 256)  0           ['max_pooling2d_13[0][0]',       \n",
      "                                                                  'conv2_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (BatchN  (None, 28, 28, 256)  1024       ['conv2_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (Acti  (None, 28, 28, 256)  0          ['conv3_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32768       ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv3_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_conv[0][0]',    \n",
      "                                                                  'conv3_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147456      ['conv3_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (BatchN  (None, 28, 28, 512)  2048       ['conv3_block3_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (Acti  (None, 28, 28, 512)  0          ['conv3_block4_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65536       ['conv3_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPaddin  (None, 30, 30, 128)  0          ['conv3_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 14, 14, 128)  147456      ['conv3_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 14, 14, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 14, 14, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_14 (MaxPooling2D  (None, 14, 14, 512)  0          ['conv3_block3_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 14, 14, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)         (None, 14, 14, 512)  0           ['max_pooling2d_14[0][0]',       \n",
      "                                                                  'conv3_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (BatchN  (None, 14, 14, 512)  2048       ['conv3_block4_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (Acti  (None, 14, 14, 512)  0          ['conv4_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131072      ['conv4_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv4_block1_preact_relu[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_conv[0][0]',    \n",
      "                                )                                 'conv4_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block1_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block2_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block2_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block3_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block3_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block4_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block4_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block4_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block4_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block4_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block5_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block5_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block5_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  589824      ['conv4_block5_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (BatchN  (None, 14, 14, 1024  4096       ['conv4_block5_out[0][0]']       \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (Acti  (None, 14, 14, 1024  0          ['conv4_block6_preact_bn[0][0]'] \n",
      " vation)                        )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262144      ['conv4_block6_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPaddin  (None, 16, 16, 256)  0          ['conv4_block6_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 7, 7, 256)    589824      ['conv4_block6_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 7, 7, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 7, 7, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d_15 (MaxPooling2D  (None, 7, 7, 1024)  0           ['conv4_block5_out[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 7, 7, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)         (None, 7, 7, 1024)   0           ['max_pooling2d_15[0][0]',       \n",
      "                                                                  'conv4_block6_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (BatchN  (None, 7, 7, 1024)  4096        ['conv4_block6_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (Acti  (None, 7, 7, 1024)  0           ['conv5_block1_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524288      ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block1_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block1_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv5_block1_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_conv[0][0]',    \n",
      "                                                                  'conv5_block1_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block1_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block2_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block2_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block2_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block2_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
      "                                                                  'conv5_block2_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (BatchN  (None, 7, 7, 2048)  8192        ['conv5_block2_out[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (Acti  (None, 7, 7, 2048)  0           ['conv5_block3_preact_bn[0][0]'] \n",
      " vation)                                                                                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1048576     ['conv5_block3_preact_relu[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPaddin  (None, 9, 9, 512)   0           ['conv5_block3_1_relu[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359296     ['conv5_block3_2_pad[0][0]']     \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
      "                                                                  'conv5_block3_3_conv[0][0]']    \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalization)   (None, 7, 7, 2048)   8192        ['conv5_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " post_relu (Activation)         (None, 7, 7, 2048)   0           ['post_bn[0][0]']                \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['post_relu[0][0]']              \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 5)            10245       ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23,575,045\n",
      "Trainable params: 10,245\n",
      "Non-trainable params: 23,564,800\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/18\n",
      "1/1 - 7s - loss: 1.7905 - accuracy: 0.0000e+00 - 7s/epoch - 7s/step\n",
      "Epoch 2/18\n",
      "1/1 - 1s - loss: 1.7054 - accuracy: 0.0000e+00 - 603ms/epoch - 603ms/step\n",
      "Epoch 3/18\n",
      "1/1 - 1s - loss: 1.6456 - accuracy: 0.0000e+00 - 582ms/epoch - 582ms/step\n",
      "Epoch 4/18\n",
      "1/1 - 1s - loss: 1.6023 - accuracy: 0.2000 - 584ms/epoch - 584ms/step\n",
      "Epoch 5/18\n",
      "1/1 - 1s - loss: 1.5684 - accuracy: 0.2000 - 582ms/epoch - 582ms/step\n",
      "Epoch 6/18\n",
      "1/1 - 1s - loss: 1.5398 - accuracy: 0.4000 - 619ms/epoch - 619ms/step\n",
      "Epoch 7/18\n",
      "1/1 - 1s - loss: 1.5131 - accuracy: 0.4000 - 648ms/epoch - 648ms/step\n",
      "Epoch 8/18\n",
      "1/1 - 1s - loss: 1.4854 - accuracy: 0.6000 - 703ms/epoch - 703ms/step\n",
      "Epoch 9/18\n",
      "1/1 - 1s - loss: 1.4550 - accuracy: 0.6000 - 681ms/epoch - 681ms/step\n",
      "Epoch 10/18\n",
      "1/1 - 1s - loss: 1.4219 - accuracy: 0.6000 - 593ms/epoch - 593ms/step\n",
      "Epoch 11/18\n",
      "1/1 - 1s - loss: 1.3875 - accuracy: 0.6000 - 661ms/epoch - 661ms/step\n",
      "Epoch 12/18\n",
      "1/1 - 1s - loss: 1.3532 - accuracy: 0.8000 - 687ms/epoch - 687ms/step\n",
      "Epoch 13/18\n",
      "1/1 - 1s - loss: 1.3201 - accuracy: 1.0000 - 633ms/epoch - 633ms/step\n",
      "Epoch 14/18\n",
      "1/1 - 1s - loss: 1.2887 - accuracy: 1.0000 - 624ms/epoch - 624ms/step\n",
      "Epoch 15/18\n",
      "1/1 - 1s - loss: 1.2589 - accuracy: 1.0000 - 601ms/epoch - 601ms/step\n",
      "Epoch 16/18\n",
      "1/1 - 1s - loss: 1.2303 - accuracy: 1.0000 - 649ms/epoch - 649ms/step\n",
      "Epoch 17/18\n",
      "1/1 - 1s - loss: 1.2023 - accuracy: 1.0000 - 692ms/epoch - 692ms/step\n",
      "Epoch 18/18\n",
      "1/1 - 1s - loss: 1.1747 - accuracy: 1.0000 - 620ms/epoch - 620ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f07c63be0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl_model=keras.applications.resnet_v2.ResNet50V2()\n",
    "tl_model.trainable=False\n",
    "\n",
    "for layer in tl_model.layers:\n",
    "    assert layer.trainable==False\n",
    "\n",
    "base_inputs=tl_model.layers[0].input\n",
    "base_ouputs=tl_model.layers[-2].output\n",
    "output=layers.Dense(5)(base_ouputs)\n",
    "\n",
    "tl_model=keras.Model(inputs=base_inputs,outputs=output)\n",
    "tl_model.compile(optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "print(tl_model.summary())\n",
    "\n",
    "train_images=tf.random.normal(shape=(5,224, 224, 3))\n",
    "train_labels=tf.constant([0,1,2,3,4])\n",
    "\n",
    "tl_model.fit(train_images,train_labels,epochs=18,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f5ca2acd7cfffe1ba430de162f968a242c109575471a8c149f67da86ddb07b1e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
